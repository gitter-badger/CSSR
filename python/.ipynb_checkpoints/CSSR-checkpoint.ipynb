{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import stats # for some initial work with the KS testing - but not currently used\n",
    "stats.kstest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mock Arguments for proof-of-concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-7312f96515fb>, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-7312f96515fb>\"\u001b[0;36m, line \u001b[0;32m10\u001b[0m\n\u001b[0;31m    class parse_node (string) = {\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "datasize = 1000\n",
    "obs = []\n",
    "for i in range(datasize):\n",
    "    obs.append(\"AB\"[i % 2])\n",
    "obs = list(obs)\n",
    "A = ['a', 'b']\n",
    "Lmax = 5\n",
    "sig = 0.7\n",
    "\n",
    "class parsetree (alphabet) = {\n",
    "    static alphabet_hashMap = {\n",
    "    }\n",
    "\n",
    "    def __init__(alphabet) = {\n",
    "        i = 0\n",
    "        for a in enumerate(alphabet):\n",
    "            alphabet_hashMap[a] = i\n",
    "            i++\n",
    "    }\n",
    "    root = [] # root::[parse_node]\n",
    "    def update_predictive_distribution(x0, x_hist) = {\n",
    "        # navigate from root to x_hist-leaf\n",
    "        # x_hist-leaf_node.update_distribution(x0)\n",
    "    }\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "class parse_node (string) = {\n",
    "    \"\"\" history = 00\n",
    "        next_x  = 1\n",
    "        001\n",
    "    \"\"\"\n",
    "    total_counts = 0\n",
    "    current_state\n",
    "    children = []\n",
    "    counts = [0,0,0,0] # == len(A)\n",
    "    history = string\n",
    "    normalized = [0,0,0,0] # == len(A)\n",
    "    def update_distribution(x_next) = {\n",
    "        i = parsetree.alphabet_hashMap[x_next]\n",
    "        counts[i] += 1\n",
    "        total_counts++\n",
    "        for k in range(0,len(normalized)):\n",
    "            normalized[k] = counts[k] / total_counts\n",
    "    }\n",
    "    # distribution_over_alphabet = history + [x_next] # P(x_next | history) => count()\n",
    "    \"\"\" take 'windows', track current depth in form of history\n",
    "        take all next \"steps\" and calculate conditional probabilities\n",
    "    \"\"\"\n",
    "\n",
    "    def change_state(s) = {\n",
    "        # s.append(this) # see null hypothesis and uncomment one\n",
    "        current_state = s\n",
    "        # we ought to update transitions here (but for phase II it's not terribly important)\n",
    "        for child in children:\n",
    "            child.change_state(s)\n",
    "    }\n",
    "}\n",
    "\n",
    "class parse_node_child (string) = {\n",
    "    \"\"\" history = 100   <= note that \"going into the past is appendleft\n",
    "        next_x  = 1\n",
    "        001\n",
    "    \"\"\"\n",
    "    history = string\n",
    "    distribution_over_alphabet = history + [x_next] # P(x_next | history) => count()\n",
    "    \"\"\" take 'windows', track current depth in form of history\n",
    "        take all next \"steps\" and calculate conditional probabilities\n",
    "        \n",
    "    \"\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse Tree substitution: window\n",
    "Instead of trying to code up the full parse tree, I opted for the moving window approach since it should take the same time complexity to parse, and about the same amount of time complexity to run the CSSR. Although given a large dataset and a relatively small state size, we should have amortized O(n) navigating the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def window(xs, l):\n",
    "    \"\"\" Instead of a parse tree, just yield successive l-sized windows from the x's.\n",
    "        Does not work with a length of 0.\n",
    "    \"\"\"\n",
    "    for i in iter(range(0, len(xs), l)):\n",
    "        yield xs[i:i+l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Sanity Checks\n",
    "# for w in window(obs, 1): print(w)\n",
    "# for w in window(obs, Lmax): print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Kolmogorov–Smirnov Test\n",
    "This was ported from CSSR but can probably be to be replaced with scipy after we get to a comfortable spot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Kolmogorov–Smirnov test ported from CSSR (to be replaced with scipy)\n",
    "\n",
    "# TODO: note to doublecheck all of this. Look up tables for control values\n",
    "def ks_test(dist1, dist1_total, dist2, dist2_total):\n",
    "    assert(len(dist1) == len(dist2))\n",
    "\n",
    "    size = len(dist1)\n",
    "\n",
    "    temp1arr = [dist1[0]]\n",
    "    temp2arr = [dist2[0]]\n",
    "\n",
    "    # obtain cumulative distributions\n",
    "    for i in range(1, size):\n",
    "        temp1arr[i] = dist1[i] + temp1arr[i-1]\n",
    "        temp2arr[i] = dist2[i] + temp2arr[i-1];\n",
    "\n",
    "    # calculate KS statistic - take max difference between 2 values\n",
    "    def find_largest_diff(max_acc, idx):\n",
    "        max_val = abs(temp1arr[idx] - temp2arr[idx]) # see if this handles floats\n",
    "        return max_val if max_val  > max_acc else max_acc\n",
    "\n",
    "    largest_diff = reduce(find_largest_diff, range(0,dist_size), 0.0)\n",
    "\n",
    "    en = sqrt((dist1_total * dist2_total) / (dist1_total + dist2_total))\n",
    "\n",
    "    # calculate significance level\n",
    "    return prob_ks((en + 0.12 + (0.11 / en)) * largest_diff);\n",
    "\n",
    "def prob_ks(alam):\n",
    "    term\n",
    "    fac = 2.0\n",
    "    acc = 0.0\n",
    "    termbf = 0.0\n",
    "    a2 = -2.0 * alam * alam\n",
    "    EPS1=0.001\n",
    "    EPS2=1.0e-8 \n",
    "    \n",
    "    for j in range(1,100):\n",
    "        term = fac* exp(a2*j*j);\n",
    "        acc += term;\n",
    "        if (abs(term) <= EPS1*termbf) or (abs(term) <= EPS2*acc):\n",
    "            return acc\n",
    "        fac = -fac\n",
    "        termbf = abs(term)\n",
    "\n",
    "    return 1.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase I - Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "S                   = None\n",
    "Translations        = None\n",
    "StringDistributions = None\n",
    "\n",
    "class StringEvent:\n",
    "    def __init__(self, char):\n",
    "        self.value = char\n",
    "        self.distribution = []\n",
    "\n",
    "def initialization():\n",
    "    global S\n",
    "    global Translations\n",
    "    global StringDistributions\n",
    "    S                   = [  [ StringEvent('') ]  ]\n",
    "    Translations        = [   None   ]\n",
    "    StringDistributions = [  [[1.0]] ]\n",
    "    # L = 0         # using a for-loop so that we don't need this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcluating Current Distributions of a State\n",
    "\n",
    "#### TODO:\n",
    "  + `currentState.index(string[j])`\n",
    "  + `currentState.getTransitions[index]` - in essence, bring in the transition tables\n",
    "  + `frequency = startState.getFrequency()`\n",
    "  + Fix the assumption that every string is actually a struct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# double Machine::CalcStringProb(char* string, HashTable2* hashtable)\n",
    "def calc_string_prob(states, string):\n",
    "    totalPerString = 0.0\n",
    "    totalPerState = 0.0\n",
    "    total = 0\n",
    "    currentState\n",
    "    startState\n",
    "    stateArraySize = len(states)\n",
    "\n",
    "    index\n",
    "    frequency\n",
    "    isNullTrans = False\n",
    "    transition\n",
    "    for state in states:\n",
    "        totalPerState = 1\n",
    "        startState = state\n",
    "        frequency = startState.getFrequency() # ???\n",
    "        currentState = startState\n",
    "        isNullTrans = False\n",
    "\n",
    "        j = 0\n",
    "        while (j < len(string) and not isNullTrans):\n",
    "            \"\"\" Quote: checks to see which state string is in; returns a pointer to the state.\n",
    "                @.@ so this is a massive check? iterate through all states, then iterate through strings in each?\n",
    "                # index = hashtable->WhichIndex(symbol);\n",
    "            \"\"\"\n",
    "            idx_of_symbol_in_state = currentState.index(string[j])\n",
    "            # get transition probability from current state\n",
    "            totalPerState = totalPerState * calc_current_distribution(currentState)[idx_of_symbol_in_state]\n",
    "\n",
    "            # make transition\n",
    "            transition_idx = currentState.getTransitions[index]\n",
    "            if (transition_idx == None):\n",
    "                totalPerState = 0.0\n",
    "                isNullTrans = True\n",
    "            else:\n",
    "                currentState = states[transition_idx]\n",
    "            j += 1\n",
    "        totalPerString += frequency * totalPerState\n",
    "    return totalPerString;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Null Hypothesis Test\n",
    "The null hypothesis is that adding an additional piece of history does not change the conditional distribution for the next observation.\n",
    "\n",
    "TODO:\n",
    "    + Everything for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-50-67c01bf10f1f>, line 35)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-50-67c01bf10f1f>\"\u001b[0;36m, line \u001b[0;32m35\u001b[0m\n\u001b[0;31m    calc_string_prob(S, ax) == ???\u001b[0m\n\u001b[0m                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Breakdown of helper functions used for testing\n",
    "# TODO: NULL HYPOTHESIS AND TRANSISTION STATES\n",
    "\n",
    "# this IS Xt.normalized\n",
    "# def estimate_added_history(Xt, ax):\n",
    "#     return \"TODO\"\n",
    "\n",
    "# this IS 'p'\n",
    "# def estimate_next_conditional_distribution(Xt, eqivClass):\n",
    "#     \"\"\" \"\"\"\n",
    "#     return \"TODO\"\n",
    "\n",
    "# this IS 's'\n",
    "# def equivalence_class_in_state(s, x_len):\n",
    "#     \"\"\" returns subset of s that matches history size \"\"\"\n",
    "#     return  [ other_x for other_x in s if len(other_x) != x_len ]\n",
    "\n",
    "# def null_hypothesis(S, s, ax):\n",
    "#     ########\n",
    "#     ######## NEED TO FACTOR IN calc_current_distribution:\n",
    "#     ######## IS IT NOW:\n",
    "#     calc_string_prob(S, ax) == ???\n",
    "#     e = equivalence_class_in_state(s)\n",
    "#     # return count( e(s, Xt[:2]_len) == Xt[1:] ) / count(  e(s, Xt[:2]_len) )\n",
    "#     ## BASICALLY THIS IS THE CRUX OF THE BLOCKER (but it also requires Transition Tables to be figured out.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restricted Hypothesis Test\n",
    "The restricted hypothesis is that we have the right set of conditional distributions, but have matched them with the wrong histories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_state(S, s):\n",
    "    \"\"\" Filter the list of all states to get states not equal to the current state for the\n",
    "        alternative hypothesis.\n",
    "        TODO: move from lists to arrays after proof-of-concept.\n",
    "    \"\"\"\n",
    "    return [other_s for other_s in S if other_s != s]\n",
    "\n",
    "def restricted_hypotheses_testing(S, s, ax, sig):\n",
    "    \"\"\" The restricted hypothesis is that we have the right set of conditional distributions,\n",
    "        but have matched them with the wrong histories.\n",
    "    \"\"\"\n",
    "    S_star = filter_state(S, s)\n",
    "    for s_star in iter(S_star):\n",
    "        if nullHypothesis(s_star, ax) > sig:\n",
    "            return s_star\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test and Move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def null_hypothesis(s, aXt):\n",
    "    ks_test(s.normalized, s.counts, aXt.normalized, aXt.total_counts)\n",
    "\n",
    "def test(S, p, aXt, s, sig):\n",
    "    if nullHypothesis(s, aXt) > sig:\n",
    "        if not aXt in s:\n",
    "            aXt.change_state(s)\n",
    "            # s.append(aXt)\n",
    "    else:\n",
    "        s_star = restricted_hypotheses_testing(S, s, aXt, sig)\n",
    "        if s_star != None:\n",
    "            move(aXt, s, s_star)\n",
    "        else:\n",
    "            s_new = state()\n",
    "            S.append(s_new)\n",
    "            move(aXt, s, s_new)\n",
    "\n",
    "def move(x, s1, s2):\n",
    "    s1.rm_history(x)\n",
    "    s2.add_history(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['a', 'b']]\n"
     ]
    }
   ],
   "source": [
    "# Sanity checks:\n",
    "print(filter_state(list([list(\"ab\"), list(\"bc\")]), list(\"bc\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase II- Sufficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fill_parse_tree():\n",
    "    for L in range(1, Lmax):\n",
    "        for Xt in window(X, L):  # window cannot be 0 => moving to parsetree\n",
    "            x0        = Xt[L-1]\n",
    "            x_history = Xt[0:L-2]\n",
    "            parsetree.update_predictive_distribution(x0, x_history)\n",
    "\n",
    "S = None\n",
    "\n",
    "def initialization():\n",
    "    global S\n",
    "    parsetree.root.change_state(0)\n",
    "    S      = [  [ parsetree.root ]  ]\n",
    "\n",
    "class state() = {\n",
    "    histories  = [] # parsetree_nodes\n",
    "    normalized_distribution = []\n",
    "    count = 0\n",
    "    \n",
    "    def add_history (h)= {\n",
    "        histories.append(h)\n",
    "        normalize_across_histories()\n",
    "    }\n",
    "\n",
    "    def rm_history (x)= {\n",
    "        histories = filter(lambda y: y != x, histories)\n",
    "        normalize_across_histories()\n",
    "    }\n",
    "\n",
    "    def normalize_across_histories() = {\n",
    "        count = 0\n",
    "        for node in histories:\n",
    "            count += node.total_count\n",
    "            normalized_distribution += node.normalized * node.total_count\n",
    "\n",
    "        normalized_distribution / count\n",
    "    }\n",
    "    \n",
    "}\n",
    "    \n",
    "def sufficiency():\n",
    "    for L in range(1,Lmax):\n",
    "        # get a list of parse_nodes with len(history) == L\n",
    "        for Xt in parse_nodes:\n",
    "            s = Xt.current_state\n",
    "            for a in A:\n",
    "                # NOTE: latent MMs\n",
    "                # node in the parse tree with predictive dist\n",
    "                aXt = Xt.children.find(lambda child: child.history[0] == a)\n",
    "                s.normalize_across_histories()\n",
    "                p = s.normalized_distribution\n",
    "                test(S, p, aXt, s, sig)\n",
    "                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase III - Recursion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def recursion ():\n",
    "    # Remove transient states from S\n",
    "    recursive = False\n",
    "    while not recursive:\n",
    "        recursive = True\n",
    "        for s in S:\n",
    "            for b in A:\n",
    "                x0 = s[0]\n",
    "                x0b = x0 + [b]\n",
    "                T_sb = equivalenceClass(x0b)   #### TODO: equivalenceClass\n",
    "                for x in s[1:]:\n",
    "                    T_xb = equivalenceClass(x + [b])\n",
    "                    if T_xb != T_sb:\n",
    "                        s_new = ['']\n",
    "                        S.append(s_new)\n",
    "                        T_s_newb = T_xb\n",
    "                        for y in s:\n",
    "                            if equivalenceClass(y + [b]) == T_s_newb:\n",
    "                                move(y, s, s_new)\n",
    "                        recursive = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'estimateAddedHistory' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-5a8eb5e054c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minitialization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msufficiency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mrecursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-47-1e69cd978086>\u001b[0m in \u001b[0;36msufficiency\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m                         \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx_history\u001b[0m \u001b[0;31m# for something immutable, others are faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                         \u001b[0;31m# TODO!!!!!!!!!!!!!!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimateAddedHistory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# P(Xt |Xt−1t−L= ax)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m                         \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#TODO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'estimateAddedHistory' is not defined"
     ]
    }
   ],
   "source": [
    "initialization()\n",
    "sufficiency()\n",
    "recursion()\n",
    "print(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
